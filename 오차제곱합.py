#가장 많이 쓰이는 손실함수  ->  오차제곱합
#y는 신경망의 출력   t는 정답레이블   k는 데이터의 차원 수
#y의 값들은 소프트맥스 함수의 값으로 확률로 나타낼 수 있다.

import numpy as np

def sum_squares_error(y, t):
    return 0.5 * np.sum((y-t)**2)

t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]

y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]

#2에 확률이 높다고 추정할때
print(sum_squares_error(np.array(y), np.array(t)))
#0.09750000000000003

#7에 확률이 높다고 추정할때
y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]
print(sum_squares_error(np.array(y), np.array(t)))
#0.5975

#2에 대한 손실함수의 출력이 작으므로 답은 2라고 할 수 있겠다.

